{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from top2vec import Top2Vec\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "from gensim.models import Phrases\n",
    "from gensim.models.phrases import Phraser\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import strip_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path('./data')\n",
    "def load(filename):\n",
    "    f = open(DATA_DIR/filename,\"rb\")\n",
    "    return pickle.load(f)\n",
    "    \n",
    "def save(data, filename):\n",
    "    with open(DATA_DIR/filename, 'wb') as handle:\n",
    "        pickle.dump(data, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_voor_tegen_index(df):\n",
    "    print(len(df))\n",
    "    stem_column = [c for c in df.columns if 'Stem_' in c and c != 'Stem_persoon']\n",
    "    stem_column_adj = [c[5:] for c in df.columns if 'Stem_' in c and c != 'Stem_persoon']\n",
    "    stem_array = df[stem_column].values.tolist()\n",
    "    assert len(stem_array[0]) == len(stem_column)\n",
    "    voor = [[stem_column_adj[i] for i, stem in enumerate(motie) if stem == 1] for motie in stem_array]\n",
    "    tegen = [[stem_column_adj[i] for i, stem in enumerate(motie) if stem == 0] for motie in stem_array]\n",
    "    df['Partijen_Voor'] = voor\n",
    "    df['Partijen_Tegen'] = tegen\n",
    "    df['Index']=list(range(len(df)))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before removal empty texts 6017\n",
      "after removal empty texts 6017\n",
      "after selecting latest cabinet 6017\n",
      "6017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gebruiker\\AppData\\Local\\Temp\\ipykernel_19916\\3808109635.py:14: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df['BesluitTekst'] = df['BesluitTekst'].str.replace('.','')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "file = open(\"moties_for_llm.pickle\",\"rb\")\n",
    "df = pickle.load(file)\n",
    "print('before removal empty texts',len(df))\n",
    "\n",
    "# remove moties without text\n",
    "mask = (df['Text']=='') | (df['Text'].isna())\n",
    "df = df.loc[~mask]\n",
    "print('after removal empty texts',len(df))\n",
    "\n",
    "df = df[df['Kabinet']=='Rutte IV']\n",
    "print('after selecting latest cabinet', len(df))\n",
    "df = add_voor_tegen_index(df)\n",
    "documents = df['ClippedText'].values\n",
    "df['BesluitTekst'] = df['BesluitTekst'].str.replace('.','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# got the code for making the bigram part from https://lppier.github.io/\n",
    "sentence_stream = [simple_preprocess(strip_tags(doc), deacc=True) for doc in documents]\n",
    "bigram = Phrases(sentence_stream, min_count=10)\n",
    "bigram_phraser = Phraser(bigram)\n",
    "\n",
    "indieners = {indiener[-1].lower() for indiener in df['Indiener_persoon'].str.split() if indiener}\n",
    "years = {word for doc in sentence_stream for word in doc if word.startswith('x') and not word.startswith('xin')}\n",
    "manual_stopwords = {'faber', 'lacin', 'kroger', 'iv', 'beschikt', 'die', 'vaststelling', 'lid','vi', 'viii', 'iii', 'iv', 'ii', 'i', 'kamer', 'regering tevens', 'regering', 'gehoord','beraadslaging'}\n",
    "stopwords = indieners | years | manual_stopwords\n",
    "   \n",
    "def bigram_stopword_preprocess(doc):\n",
    "    sentence_stream = simple_preprocess(strip_tags(doc), deacc=True)\n",
    "    sentence_stream = [word for word in sentence_stream if word not in stopwords]\n",
    "    return bigram_phraser[sentence_stream]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-04 11:32:29,496 - top2vec - INFO - Pre-processing documents for training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Programmeren\\adventofcode\\.aocenvpy311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "2023-08-04 11:32:31,006 - top2vec - INFO - Downloading distiluse-base-multilingual-cased model\n",
      "2023-08-04 11:32:32,141 - top2vec - INFO - Creating joint document/word embedding\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\Programmeren\\projects\\kamermoties\\3_top2vec_analysis.ipynb Cell 8\u001b[0m in \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Programmeren/projects/kamermoties/3_top2vec_analysis.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# https://github.com/scikit-learn-contrib/hdbscan/issues/607\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Programmeren/projects/kamermoties/3_top2vec_analysis.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m model \u001b[39m=\u001b[39m Top2Vec(documents, speed\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mdeep-learn\u001b[39;49m\u001b[39m'\u001b[39;49m, tokenizer\u001b[39m=\u001b[39;49mbigram_stopword_preprocess, embedding_model\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mdistiluse-base-multilingual-cased\u001b[39;49m\u001b[39m'\u001b[39;49m,workers\u001b[39m=\u001b[39;49m\u001b[39m8\u001b[39;49m, min_count\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m, ngram_vocab\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Programmeren/projects/kamermoties/3_top2vec_analysis.ipynb#X10sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m model\u001b[39m.\u001b[39mget_num_topics()\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Programmeren/projects/kamermoties/3_top2vec_analysis.ipynb#X10sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# removed \u001b[39;00m\n",
      "File \u001b[1;32md:\\Programmeren\\adventofcode\\.aocenvpy311\\Lib\\site-packages\\top2vec\\Top2Vec.py:618\u001b[0m, in \u001b[0;36mTop2Vec.__init__\u001b[1;34m(self, documents, min_count, topic_merge_delta, ngram_vocab, ngram_vocab_args, embedding_model, embedding_model_path, embedding_batch_size, split_documents, document_chunker, chunk_length, max_num_chunks, chunk_overlap_ratio, chunk_len_coverage_ratio, sentencizer, speed, use_corpus_file, document_ids, keep_documents, workers, tokenizer, use_embedding_model_tokenizer, umap_args, hdbscan_args, verbose)\u001b[0m\n\u001b[0;32m    616\u001b[0m \u001b[39m# embed words\u001b[39;00m\n\u001b[0;32m    617\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mword_indexes \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\u001b[39mzip\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvocab, \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvocab))))\n\u001b[1;32m--> 618\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mword_vectors \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_embed_documents(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvocab, embedding_batch_size)\n\u001b[0;32m    620\u001b[0m \u001b[39m# embed documents\u001b[39;00m\n\u001b[0;32m    621\u001b[0m \n\u001b[0;32m    622\u001b[0m \u001b[39m# split documents\u001b[39;00m\n\u001b[0;32m    623\u001b[0m \u001b[39mif\u001b[39;00m split_documents:\n",
      "File \u001b[1;32md:\\Programmeren\\adventofcode\\.aocenvpy311\\Lib\\site-packages\\top2vec\\Top2Vec.py:801\u001b[0m, in \u001b[0;36mTop2Vec._embed_documents\u001b[1;34m(self, train_corpus, batch_size)\u001b[0m\n\u001b[0;32m    798\u001b[0m     document_vectors \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_l2_normalize(np\u001b[39m.\u001b[39marray(np\u001b[39m.\u001b[39mvstack(document_vectors)))\n\u001b[0;32m    800\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 801\u001b[0m     document_vectors \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_l2_normalize(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membed(train_corpus, batch_size\u001b[39m=\u001b[39;49mbatch_size))\n\u001b[0;32m    803\u001b[0m \u001b[39mreturn\u001b[39;00m document_vectors\n",
      "File \u001b[1;32md:\\Programmeren\\adventofcode\\.aocenvpy311\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:165\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[1;34m(self, sentences, batch_size, show_progress_bar, output_value, convert_to_numpy, convert_to_tensor, device, normalize_embeddings)\u001b[0m\n\u001b[0;32m    162\u001b[0m features \u001b[39m=\u001b[39m batch_to_device(features, device)\n\u001b[0;32m    164\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m--> 165\u001b[0m     out_features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(features)\n\u001b[0;32m    167\u001b[0m     \u001b[39mif\u001b[39;00m output_value \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtoken_embeddings\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    168\u001b[0m         embeddings \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32md:\\Programmeren\\adventofcode\\.aocenvpy311\\Lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32md:\\Programmeren\\adventofcode\\.aocenvpy311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\Programmeren\\adventofcode\\.aocenvpy311\\Lib\\site-packages\\sentence_transformers\\models\\Transformer.py:66\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[1;34m(self, features)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mtoken_type_ids\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m features:\n\u001b[0;32m     64\u001b[0m     trans_features[\u001b[39m'\u001b[39m\u001b[39mtoken_type_ids\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m features[\u001b[39m'\u001b[39m\u001b[39mtoken_type_ids\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m---> 66\u001b[0m output_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mauto_model(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mtrans_features, return_dict\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m     67\u001b[0m output_tokens \u001b[39m=\u001b[39m output_states[\u001b[39m0\u001b[39m]\n\u001b[0;32m     69\u001b[0m features\u001b[39m.\u001b[39mupdate({\u001b[39m'\u001b[39m\u001b[39mtoken_embeddings\u001b[39m\u001b[39m'\u001b[39m: output_tokens, \u001b[39m'\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m'\u001b[39m: features[\u001b[39m'\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m'\u001b[39m]})\n",
      "File \u001b[1;32md:\\Programmeren\\adventofcode\\.aocenvpy311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\Programmeren\\adventofcode\\.aocenvpy311\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:608\u001b[0m, in \u001b[0;36mDistilBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    604\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m    606\u001b[0m embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings(input_ids, inputs_embeds)  \u001b[39m# (bs, seq_length, dim)\u001b[39;00m\n\u001b[1;32m--> 608\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransformer(\n\u001b[0;32m    609\u001b[0m     x\u001b[39m=\u001b[39;49membeddings,\n\u001b[0;32m    610\u001b[0m     attn_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[0;32m    611\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[0;32m    612\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m    613\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[0;32m    614\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[0;32m    615\u001b[0m )\n",
      "File \u001b[1;32md:\\Programmeren\\adventofcode\\.aocenvpy311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\Programmeren\\adventofcode\\.aocenvpy311\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:375\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[1;34m(self, x, attn_mask, head_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    368\u001b[0m     layer_outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[0;32m    369\u001b[0m         create_custom_forward(layer_module),\n\u001b[0;32m    370\u001b[0m         hidden_state,\n\u001b[0;32m    371\u001b[0m         attn_mask,\n\u001b[0;32m    372\u001b[0m         head_mask[i],\n\u001b[0;32m    373\u001b[0m     )\n\u001b[0;32m    374\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 375\u001b[0m     layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[0;32m    376\u001b[0m         hidden_state,\n\u001b[0;32m    377\u001b[0m         attn_mask,\n\u001b[0;32m    378\u001b[0m         head_mask[i],\n\u001b[0;32m    379\u001b[0m         output_attentions,\n\u001b[0;32m    380\u001b[0m     )\n\u001b[0;32m    382\u001b[0m hidden_state \u001b[39m=\u001b[39m layer_outputs[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m    384\u001b[0m \u001b[39mif\u001b[39;00m output_attentions:\n",
      "File \u001b[1;32md:\\Programmeren\\adventofcode\\.aocenvpy311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\Programmeren\\adventofcode\\.aocenvpy311\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:295\u001b[0m, in \u001b[0;36mTransformerBlock.forward\u001b[1;34m(self, x, attn_mask, head_mask, output_attentions)\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    286\u001b[0m \u001b[39mParameters:\u001b[39;00m\n\u001b[0;32m    287\u001b[0m \u001b[39m    x: torch.tensor(bs, seq_length, dim)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    292\u001b[0m \u001b[39m    torch.tensor(bs, seq_length, dim) The output of the transformer block contextualization.\u001b[39;00m\n\u001b[0;32m    293\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    294\u001b[0m \u001b[39m# Self-Attention\u001b[39;00m\n\u001b[1;32m--> 295\u001b[0m sa_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattention(\n\u001b[0;32m    296\u001b[0m     query\u001b[39m=\u001b[39;49mx,\n\u001b[0;32m    297\u001b[0m     key\u001b[39m=\u001b[39;49mx,\n\u001b[0;32m    298\u001b[0m     value\u001b[39m=\u001b[39;49mx,\n\u001b[0;32m    299\u001b[0m     mask\u001b[39m=\u001b[39;49mattn_mask,\n\u001b[0;32m    300\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[0;32m    301\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m    302\u001b[0m )\n\u001b[0;32m    303\u001b[0m \u001b[39mif\u001b[39;00m output_attentions:\n\u001b[0;32m    304\u001b[0m     sa_output, sa_weights \u001b[39m=\u001b[39m sa_output  \u001b[39m# (bs, seq_length, dim), (bs, n_heads, seq_length, seq_length)\u001b[39;00m\n",
      "File \u001b[1;32md:\\Programmeren\\adventofcode\\.aocenvpy311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\Programmeren\\adventofcode\\.aocenvpy311\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:215\u001b[0m, in \u001b[0;36mMultiHeadSelfAttention.forward\u001b[1;34m(self, query, key, value, mask, head_mask, output_attentions)\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[39m\"\"\"group heads\"\"\"\u001b[39;00m\n\u001b[0;32m    213\u001b[0m     \u001b[39mreturn\u001b[39;00m x\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m)\u001b[39m.\u001b[39mcontiguous()\u001b[39m.\u001b[39mview(bs, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_heads \u001b[39m*\u001b[39m dim_per_head)\n\u001b[1;32m--> 215\u001b[0m q \u001b[39m=\u001b[39m shape(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mq_lin(query))  \u001b[39m# (bs, n_heads, q_length, dim_per_head)\u001b[39;00m\n\u001b[0;32m    216\u001b[0m k \u001b[39m=\u001b[39m shape(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mk_lin(key))  \u001b[39m# (bs, n_heads, k_length, dim_per_head)\u001b[39;00m\n\u001b[0;32m    217\u001b[0m v \u001b[39m=\u001b[39m shape(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mv_lin(value))  \u001b[39m# (bs, n_heads, k_length, dim_per_head)\u001b[39;00m\n",
      "File \u001b[1;32md:\\Programmeren\\adventofcode\\.aocenvpy311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\Programmeren\\adventofcode\\.aocenvpy311\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# https://github.com/scikit-learn-contrib/hdbscan/issues/607\n",
    "model = Top2Vec(documents, speed='deep-learn', tokenizer=bigram_stopword_preprocess, embedding_model='distiluse-base-multilingual-cased',workers=8, min_count=5, ngram_vocab=False)\n",
    "model.get_num_topics()\n",
    "\n",
    "# removed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"data/doc2vec_deep_bigram_enhanced_stopwords_rutteIV\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce topic number to something more manageable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before removal empty texts 6017\n",
      "after removal empty texts 6017\n",
      "after selecting latest cabinet 6017\n",
      "6017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gebruiker\\AppData\\Local\\Temp\\ipykernel_19916\\3755217826.py:14: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df['BesluitTekst'] = df['BesluitTekst'].str.replace('.','')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "file = open(\"moties_for_llm.pickle\",\"rb\")\n",
    "df = pickle.load(file)\n",
    "print('before removal empty texts',len(df))\n",
    "\n",
    "# remove moties without text\n",
    "mask = (df['Text']=='') | (df['Text'].isna())\n",
    "df = df.loc[~mask]\n",
    "print('after removal empty texts',len(df))\n",
    "\n",
    "df = df[df['Kabinet']=='Rutte IV']\n",
    "print('after selecting latest cabinet', len(df))\n",
    "df = add_voor_tegen_index(df)\n",
    "documents = df['ClippedText'].values\n",
    "df['BesluitTekst'] = df['BesluitTekst'].str.replace('.','')\n",
    "model = Top2Vec.load(\"data/doc2vec_deep_bigram_enhanced_stopwords_rutteIV\")\n",
    "model.get_num_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_sizes, topic_nums = model.get_topic_sizes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reduced_topics(num_topics):\n",
    "    print(f'performing reduction to {num_topics} topics')\n",
    "    reduced_topics = model.hierarchical_topic_reduction(num_topics)\n",
    "    topic_words, word_scores, topic_nums = model.get_topics(reduced=True)\n",
    "    reduced_topics = tuple(tuple(sorted(t)) for t in reduced_topics)\n",
    "    return reduced_topics, topic_words\n",
    "\n",
    "def find_diff(reduced1, reduced2, reverse=False):\n",
    "    # find the topics that where merged and return their index\n",
    "    if not reverse:\n",
    "        changed = set(reduced1) - set(reduced2)\n",
    "        return [index for index, topic in enumerate(reduced1) if topic in changed]\n",
    "    else:\n",
    "        changed = set(reduced2) - set(reduced1)\n",
    "        return [index for index, topic in enumerate(reduced2) if topic in changed]\n",
    "\n",
    "\n",
    "def print_merge(large, small, num_words=50):\n",
    "    print(f'\\ninspecting difference from {len(large[0])} to {len(small[0])} topics')\n",
    "    print('old topics')\n",
    "    for i in find_diff(large[0],small[0]):\n",
    "        print(large[1][i][:num_words])\n",
    "    print('new topic')\n",
    "    for i in find_diff(large[0],small[0], reverse=True):\n",
    "        print(small[1][i][:num_words])\n",
    "\n",
    "def find_optimal_num_topics():\n",
    "    start = 46\n",
    "    stop = 35\n",
    "    reductions = {i: get_reduced_topics(i) for i in range(start, stop, -1)}\n",
    "    for i in range(start, stop +1,-1):\n",
    "        print(i)\n",
    "        print_merge(reductions[i], reductions[i-1])\n",
    "# find_optimal_num_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a choice to how many topics to reduce\n",
    "num_topics = 46\n",
    "reduced_topics = model.hierarchical_topic_reduction(num_topics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect number of documents for each topic\n",
    "# topic_sizes, topic_nums = model.get_topic_sizes(reduced=True)\n",
    "topic_words, word_scores, topic_nums = model.get_topics(reduced=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20, 23, 36, 38], dtype=int64)"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_words, word_scores, topic_scores, topic_nums = model.search_topics(keywords= ['politie'] , num_topics=4, reduced=True)\n",
    "topic_nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(topic_nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = {\n",
    "  0: 'Onderwijs',  \n",
    "  1: 'Buitenlandse zaken',  \n",
    "  2: 'Algemene zaken',  \n",
    "  3: 'Natuur & gaswinning',  \n",
    "  4: 'Landbouw & dierenwelzijn',  \n",
    "  5: 'Zorg',  \n",
    "  6: 'Sociale zaken',  \n",
    "  7: 'Justitie',  \n",
    "  8: 'Pensioenstelsel',  \n",
    "  9: 'Europese Unie',  \n",
    "  10: 'Klimaat & energie',  \n",
    "  11: 'Milieu & regelgeving',  \n",
    "  12: 'Zorg',  \n",
    "  13: 'Openbaar vervoer',  \n",
    "  14: 'Financiele sector',  \n",
    "  15: 'Wonen'\n",
    "  }\n",
    "topic_words, word_scores, topic_nums = model.get_topics()\n",
    "topics = {i:' '.join(topic_words[i][:3]) for i in range(len(topic_words))}\n",
    "doc_ids = list(range(len(documents)))\n",
    "topic_nums, topic_score, topic_words, word_scores = model.get_documents_topics(doc_ids,reduced=True)\n",
    "topic_names = [topics[t] for t in topic_nums]\n",
    "assert len(topic_nums) == len(df)\n",
    "df['Topic'] = topic_names\n",
    "topic_nums, topic_score, topic_words, word_scores = model.get_documents_topics(doc_ids,reduced=False)\n",
    "df['Topic_initial'] = topic_nums\n",
    "df['Topic_score'] = topic_score\n",
    "# df.sort_values(['Topic_initial', 'Topic_score'], ascending=False, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional add climate deepdive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_sizes, topic_nums = model.get_topic_sizes(reduced=False)\n",
    "topic_words, word_scores, topic_nums = model.get_topics(reduced=False)\n",
    "climate_idx = [topic_nums for t in topic_nums if t in reduced_topics[10]]\n",
    "climate_subtopics = {128: 'Afhankelijkheid fossiele brandstoffen',\n",
    " 165: 'CO2 reductie',\n",
    " 5: 'Voldoen aan Parijs',\n",
    " 141: 'Electriciteit',\n",
    " 126: 'Groningen',\n",
    " 205: 'Zonnepanelen',\n",
    " 96: 'Energierekening betalen',\n",
    " 236: 'Biomassa',\n",
    " 105: 'Kolencentrales',\n",
    " 239: 'Windturbines - overlast',\n",
    " 29: 'Windturbines - subsidie'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Klimaat'] = df.loc[df['Topic']=='Klimaat & energie', 'Topic_initial'].map(climate_subtopics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(df[:1000], 'df_including_topics.pickle')\n",
    "save(df, 'df_including_topics_full.pickle')\n",
    "save(model, 'doc2vec_deep_bigram_enhanced_stopwords_rutteIV_reduced')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6017"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare slimmed down versions for production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gebruiker\\AppData\\Local\\Temp\\ipykernel_19916\\1140064191.py:2: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df['BesluitTekst'] = df['BesluitTekst'].str.replace('.','')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6017\n",
      "6017\n"
     ]
    }
   ],
   "source": [
    "df = load(\"df_including_topics_full.pickle\")\n",
    "df['BesluitTekst'] = df['BesluitTekst'].str.replace('.','')\n",
    "\n",
    "print(len(df))\n",
    "\n",
    "model = Top2Vec.load(\"data/doc2vec_deep_bigram_enhanced_stopwords_rutteIV_reduced\")\n",
    "reduced_topics = model.hierarchical_topic_reduction(10)\n",
    "\n",
    "doc_ids = list(range(len(df)))\n",
    "# don't sort the df before this operation\n",
    "topic_nums, topic_score, topic_words, word_scores = model.get_documents_topics(doc_ids,reduced=True)\n",
    "topics = [t[0] for t in topic_words]\n",
    "\n",
    "df['Topic_initial'] = topics\n",
    "df['Topic_score'] = topic_score\n",
    "df.sort_values(['Topic_initial', 'Topic_score'], ascending=False, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "df = df[df['Kamer']=='Rutte IV']\n",
    "print(len(df))\n",
    "# important do this only after all row filters have been set\n",
    "df.index = df['Index']\n",
    "\n",
    "\n",
    "stem_column = [c for c in df.columns if 'Stem_' in c and c != 'Stem_persoon']\n",
    "required_cols = ['Kamer', 'Jaar','Indienende_partij', 'BesluitSoort','BesluitTekst','Topic_initial', 'Topic_score','Indienende_persoon_partij','Partijen_Voor', 'Partijen_Tegen', 'Text']\n",
    "\n",
    "# streamlit has problems with category type: \n",
    "# https://github.com/streamlit/streamlit/issues/47\n",
    "# for col in stem_column + required_cols[:-4]:\n",
    "#     df[col] = df[col].astype('category')\n",
    "\n",
    "df = df[stem_column + required_cols]\n",
    "save(df, \"df_production.pickle\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 7, 6, 9], dtype=int64)"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "topic_words, word_scores, topic_scores, topic_nums = model.search_topics(keywords= ['politie'] , num_topics=4, reduced=True)\n",
    "topic_nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_documents(self, doc_ids):\n",
    "    \"\"\"\n",
    "    Delete documents from current model.\n",
    "    Warning: If document ids were not used in original model, deleting\n",
    "    documents will change the indexes and therefore doc_ids.\n",
    "    The documents will be deleted from the current model without changing\n",
    "    existing document, word and topic vectors. Topic sizes will be updated.\n",
    "    If deleting a large quantity of documents relative to the current model\n",
    "    size a new model should be trained for best results.\n",
    "    Parameters\n",
    "    ----------\n",
    "    doc_ids: List of str, int\n",
    "        A unique value per document that is used for referring to documents\n",
    "        in search results.\n",
    "    \"\"\"\n",
    "    # make sure documents exist\n",
    "    self._validate_doc_ids(doc_ids, doc_ids_neg=[])\n",
    "\n",
    "    # update index\n",
    "    if self.documents_indexed:\n",
    "        # delete doc_ids from index\n",
    "        index_ids = [self.doc_id2index_id(doc_id) for doc_id in doc_ids]\n",
    "        for index_id in index_ids:\n",
    "            self.document_index.mark_deleted(index_id)\n",
    "        # update index_id and doc_ids\n",
    "        for doc_id in doc_ids:\n",
    "            self.doc_id2index_id.pop(doc_id)\n",
    "        for index_id in index_ids:\n",
    "            self.index_id2doc_id.pop(index_id)\n",
    "\n",
    "    # get document indexes from ids\n",
    "    doc_indexes = self._get_document_indexes(doc_ids)\n",
    "\n",
    "    # delete documents\n",
    "    if self.documents is not None:\n",
    "        self.documents = np.delete(self.documents, doc_indexes, 0)\n",
    "\n",
    "    # delete document ids\n",
    "    if self.document_ids is not None:\n",
    "        for doc_id in doc_ids:\n",
    "            self.doc_id2index.pop(doc_id)\n",
    "        keys = list(self.doc_id2index.keys())\n",
    "        self.document_ids = np.array(keys)\n",
    "        values = list(range(0, len(self.doc_id2index.values())))\n",
    "        self.doc_id2index = dict(zip(keys, values))\n",
    "\n",
    "    # delete document vectors\n",
    "    self._set_document_vectors(np.delete(self._get_document_vectors(norm=False), doc_indexes, 0))\n",
    "\n",
    "    if self.embedding_model == 'doc2vec':\n",
    "        num_docs = len(doc_indexes)\n",
    "        self.model.docvecs.count -= num_docs\n",
    "        self.model.docvecs.max_rawint -= num_docs\n",
    "        self.model.docvecs.vectors_docs_norm = None\n",
    "        self.model.docvecs.init_sims()\n",
    "\n",
    "    # update topics\n",
    "    # self._unassign_documents_from_topic(doc_indexes, hierarchy=False)\n",
    "\n",
    "    if self.hierarchy is not None:\n",
    "        self._unassign_documents_from_topic(doc_indexes, hierarchy=True)\n",
    "model = Top2Vec.load(\"data/doc2vec_deep_bigram_enhanced_stopwords_rutteIV_reduced\")\n",
    "\n",
    "# model.delete_documents = delete_documents\n",
    "df = load(\"df_including_topics_full.pickle\")\n",
    "model.delete_documents(list(range(len(df))))\n",
    "model.delete_documents = 1\n",
    "model.save(\"data/doc2vec_production\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([44, 23, 13, 15], dtype=int64)"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_words, word_scores, topic_scores, topic_nums = model.search_topics(keywords= ['politie'] , num_topics=4, reduced=True)\n",
    "topic_nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([44, 23, 13, 15], dtype=int64)"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = load(\"df_production.pickle\")\n",
    "model = Top2Vec.load(\"data/doc2vec_production\")\n",
    "topic_words, word_scores, topic_scores, topic_nums = model.search_topics(keywords= ['politie'] , num_topics=4, reduced=True)\n",
    "topic_nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_words, word_scores, topic_nums = model.get_topics(num_topics=47)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['politieagenten', 'politietop', 'politiemensen', 'politiewet',\n",
       "       'politieacademie', 'polisaanbod', 'politie', 'polissen', 'cop',\n",
       "       'zedenpolitie', 'overheidsbeleid', 'regeringsbeleid',\n",
       "       'kabinetsbeleid', 'georganiseerde_criminaliteit',\n",
       "       'openbaar_ministerie', 'asielbeleid', 'nationale_veiligheid',\n",
       "       'bureaucratische', 'autoriteiten', 'landenbeleid', 'beleidskader',\n",
       "       'rijksbeleid', 'bureaucratie', 'beleidsopties',\n",
       "       'ministeriele_regeling', 'politici', 'loonbeleid', 'beleidsinzet',\n",
       "       'administratieve_lasten', 'sanctiebeleid', 'decentrale_overheden',\n",
       "       'politieke_partijen', 'politiek', 'politieke', 'beleids',\n",
       "       'agenten', 'beleid', 'beleidskeuze', 'industriebeleid',\n",
       "       'beleidskeuzes', 'preventiebeleid', 'beleidsnota', 'agentschap',\n",
       "       'beleidsregels', 'bestuursorganen', 'beleidsmatige',\n",
       "       'beleidsvrijheid', 'openbare_orde', 'nederlandse_zorgautoriteit',\n",
       "       'beleidslijn'], dtype='<U28')"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_words[45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6017"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = load(\"df_production.pickle\")\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2\\nTweede Kamer der Staten-Generaal\\nVergaderjaar 2021–2022\\n32 813 Kabinetsaanpak Klimaatbeleid\\nNr. 1013 MOTIE VAN DE LEDEN BONTENBAL EN GRINWIS\\nVoorgesteld 19 april 2022\\nDe Kamer,\\ngehoord de beraadslaging,\\noverwegende dat de verduurzaming van de gebouwde omgeving de\\nkomende jaren vooral gefocust moet zijn op het verduurzamen van de\\nwarmtevoorziening in de gebouwde omgeving, resulterend in een\\nreductie van het aardgasverbruik;\\nverzoekt de regering om in het beleid voor de verduurzaming van de\\ngebouwde omgeving ook een subdoelstelling voor aardgasreductie op te\\nnemen,\\nen gaat over tot de orde van de dag.\\nBontenbal\\nGrinwis\\nkst-32813-1013ISSN\\n0921 - 7371\\n’s-Gravenhage 2022 Tweede Kamer, vergaderjaar 2021–2022, 32 813, nr. 1013'"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df['Topic_initial']=='verduurzamen') & (df['Kamer']=='Rutte IV')]['Text'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6017\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Aangenomen    3296\n",
       "Verworpen     2721\n",
       "Name: BesluitTekst, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = load(\"df_including_topics_full.pickle\")\n",
    "print(len(df))\n",
    "df['BesluitTekst'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "necessary = load(\"df_production.pickle\")\n",
    "necessary_idx = set(necessary.index)\n",
    "\n",
    "full = load(\"df_including_topics_full.pickle\")\n",
    "full_idx = set(full['Index'])\n",
    "\n",
    "redundant_idx = full_idx - necessary_idx\n",
    "assert len(necessary_idx) + len(redundant_idx) == len(full_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0], dtype=int64),\n",
       " array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "         13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "         26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "         39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "         52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "         65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "         91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "        104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "        117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
       "        130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
       "        143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
       "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
       "        169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
       "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
       "        195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n",
       "        208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n",
       "        221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
       "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246],\n",
       "       dtype=int64))"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_topic_sizes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([22728,  9991,  5958,  2969,  6021,  8364, 19787,  8385,  8357,\n",
       "       16140])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Top2Vec.load(\"data/doc2vec_deep_bigram_enhanced_stopwords\")\n",
    "documents, document_scores, document_ids = model.search_documents_by_topic(topic_num =3, num_docs= 100)\n",
    "document_ids[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_remove_3 = full[(full['Topic_initial']==3)&(full['Index'].isin(redundant_idx))]['Index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "278"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(to_remove_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[531 458 445 404 401 350 347 333 326 312 309 308 301 287 285 278 276 273\n",
      " 270 265 263 257 255 240 236 230 230 228 227 222 220 211 205 205 203 199\n",
      " 197 195 193 192 190 182 181 180 175 174 171 169 166 165 164 163 161 159\n",
      " 159 159 158 156 155 154 154 151 151 150 150 148 147 143 141 141 136 134\n",
      " 133 133 132 131 129 127 126 125 124 124 122 121 120 118 118 118 117 116\n",
      " 114 113 112 110 109 108 108 107 107 105 105 103 103 103 102 100  99  98\n",
      "  98  97  96  96  96  96  96  96  95  95  95  94  93  91  91  91  89  88\n",
      "  88  88  87  87  86  86  86  85  85  84  84  84  83  83  81  81  81  81\n",
      "  80  80  80  80  79  79  79  79  79  79  78  77  76  75  75  75  75  74\n",
      "  73  72  72  71  71  70  70  69  69  68  68  68  67  67  67  67  65  65\n",
      "  65  64  63  62  62  61  60  60  59  59  58  58  57  57  57  56  56  56\n",
      "  56  55  55  55  54  54  53  52  52  52  52  52  50  50  49  48  47  47\n",
      "  46  46  46  45  45  45  45  45  45  44  44  43  43  42  41  41  40  40\n",
      "  39  38  38  38  37  36  35  34  34  33  33  32  23]\n",
      "[531 458 445 401 350 347 333 326 312 309 308 301 287 285 278 276 273 270\n",
      " 265 263 257 255 240 236 230 230 228 227 222 220 211 205 205 203 199 197\n",
      " 195 193 192 190 182 181 180 175 174 171 169 166 165 164 163 161 159 159\n",
      " 159 158 156 155 154 154 151 151 150 150 148 147 143 141 141 136 134 133\n",
      " 133 132 131 129 127 126 126 125 124 124 122 121 120 118 118 118 117 116\n",
      " 114 113 112 110 109 108 108 107 107 105 105 103 103 103 102 100  99  98\n",
      "  98  97  96  96  96  96  96  96  95  95  95  94  93  91  91  91  89  88\n",
      "  88  88  87  87  86  86  86  85  85  84  84  84  83  83  81  81  81  81\n",
      "  80  80  80  80  79  79  79  79  79  79  78  77  76  75  75  75  75  74\n",
      "  73  72  72  71  71  70  70  69  69  68  68  68  67  67  67  67  65  65\n",
      "  65  64  63  62  62  61  60  60  59  59  58  58  57  57  57  56  56  56\n",
      "  56  55  55  55  54  54  53  52  52  52  52  52  50  50  49  48  47  47\n",
      "  46  46  46  45  45  45  45  45  45  44  44  43  43  42  41  41  40  40\n",
      "  39  38  38  38  37  36  35  34  34  33  33  32  23]\n"
     ]
    }
   ],
   "source": [
    "model = Top2Vec.load(\"data/doc2vec_deep_bigram_enhanced_stopwords\")\n",
    "print(model.get_topic_sizes()[0])\n",
    "model.delete_documents(list(to_remove_3))\n",
    "print(model.get_topic_sizes()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid number of documents: original topic 3 only has 0 documents.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-129-1cb2ef9b984a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# model = Top2Vec.load(\"data/doc2vec_deep_bigram_enhanced_stopwords\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdocument_scores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdocument_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch_documents_by_topic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtopic_num\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_docs\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m404\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreturn_documents\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\top2vec\\Top2Vec.py\u001b[0m in \u001b[0;36msearch_documents_by_topic\u001b[1;34m(self, topic_num, num_docs, return_documents, reduced)\u001b[0m\n\u001b[0;32m   1736\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1737\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_topic_num\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtopic_num\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduced\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1738\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_topic_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtopic_num\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_docs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduced\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1739\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1740\u001b[0m             \u001b[0mtopic_document_indexes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdoc_top\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mtopic_num\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\top2vec\\Top2Vec.py\u001b[0m in \u001b[0;36m_validate_topic_search\u001b[1;34m(self, topic_num, num_docs, reduced)\u001b[0m\n\u001b[0;32m    869\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    870\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mnum_docs\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtopic_sizes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtopic_num\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 871\u001b[1;33m                 raise ValueError(f\"Invalid number of documents: original topic {topic_num}\"\n\u001b[0m\u001b[0;32m    872\u001b[0m                                  f\" only has {self.topic_sizes[topic_num]} documents.\")\n\u001b[0;32m    873\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid number of documents: original topic 3 only has 0 documents."
     ]
    }
   ],
   "source": [
    "# model = Top2Vec.load(\"data/doc2vec_deep_bigram_enhanced_stopwords\")\n",
    "document_scores, document_ids = model.search_documents_by_topic(topic_num =3, num_docs= 404,return_documents=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29484"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Top2Vec.load(\"data/doc2vec_deep_bigram_enhanced_stopwords\")\n",
    "sums, _ = model.get_topic_sizes()\n",
    "sum(sums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2\\nTweede Kamer der Staten-Generaal\\nVergaderjaar 2019–2020 \\n35 420 Noodpakket banen en economie \\nNr. 66   MOTIE VAN DE LEDEN BAUDET EN VAN HAGA \\nVoorgesteld 28 mei 2020 \\nDe Kamer, \\ngehoord de beraadslaging, \\nconstaterende dat in 2019 de Klimaatwet in werking is getreden; \\noverwegende dat de kosten van het Nederlandse klimaatbeleid naar \\nverwachting zullen oplopen tot in totaal 1.000 miljard euro; \\noverwegende dat het Nederlandse klimaatbeleid, zelfs als de theorie over \\nopwarming van de aarde door toedoen van de mens zou kloppen, die \\nopwarming met hoogstens 0,00007 graden zou beperken; \\noverwegende dat de kosten van het klimaatbeleid in geen enkele \\nverhouding staan tot de opbrengsten; \\nroept de regering op, om het klimaatbeleid te staken en het geld dat \\nhierdoor bespaard wordt in te zetten om de klappen van de coronacrisis \\nop te vangen, \\nen gaat over tot de orde van de dag. \\nBaudet \\nVan Haga\\n \\n \\n \\n \\nkst-35420-66\\nISSN 0921 - 7371\\n’s-Gravenhage 2020 Tweede Kamer, vergaderjaar 2019–2020, 35 420, nr. 66'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(necessary[necessary['Topic_initial']==3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load('df_production.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2020, 2019, 2018, 2017], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Jaar'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['2017', '2018', '2019', '2020']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "ecf5722fdaf1897a315d257d89d94520bfcaa453217d5becf09b39e73618b0de"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
